# -*- coding: utf-8 -*-
"""SBI stock market using different algorithm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Lw74D_fWFKyfffTHlAe_8eczvD6Ji0HB
"""

#SBI stock market using multiple regression

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from mpl_toolkits.mplot3d import Axes3D

import warnings
warnings.filterwarnings('ignore')

data = pd.read_csv('stock market.csv')
data.head()

print(data.describe(),'\n\n')
print(data.dtypes)

print(data.head())

data.rename(columns = {'Open':'started','High':'Highest','Low':'Lowest','Change %':'chg%'},inplace=True)
print(data.head())

plt.plot(data['Highest'])

plt.plot(data['Lowest'])

plt.plot(data['chg%'])

sns.pairplot(data)

X = data.iloc[:,:-1].values
y = data.iloc[:,:-1].values
z = data.iloc[:,].values

data.shape, X.shape,y.shape,z.shape

X_train,X_test,y_train,y_test,z_train,z_test = train_test_split(X,y,z,test_size=0.25,random_state=1)

X_train[:, 1], X_train[:, 2], X_train[:, 3]

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=1)

from sklearn.linear_model import LinearRegression
lr = LinearRegression()

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import numpy as np
import matplotlib.pyplot as plt

from mpl_toolkits.mplot3d import axes3d
import matplotlib.pyplot as plt
import numpy as np

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
X, y, z= np.array([308.05, 327.55, 263.2, 281.2, 265.45, 321.8, 303.5, 274.5, 299.6,
        285.25, 352.4, 322.75, 342.6, 286.55, 315.75, 312.1, 293.65, 296.3,
        306.2, 291.35, 343.8, 298.05, 272.95, 268.2, 280.6, 355.45, 270.5,
        270.15, 275.4, 347.1, 254.15, 361.25, 290.9, 282.55, 286.85,
        284.65, 308.75, 370.65, 277.4, 292.15, 283.6, 285.35, 287.45,
        344.7, 319.0, 273.95, 256.05, 314.3, 294.95, 284.4, 284.9, 255.65,
        294.15, 332.2, 341.3, 283.25, 261.1, 336.9, 268.0, 283.7, 289.5,
        337.85, 329.0, 309.95, 340.05, 303.15, 359.5, 281.25, 349.4,
        294.05, 288.05, 354.2, 299.3, 267.7, 300.7, 275.45, 263.75, 280.5,
        268.4, 287.4, 344.3, 273.95, 283.45, 285.9, 305.3, 278.05, 363.65,
        281.2, 284.65, 295.9, 305.3, 318.15, 302.75, 313.55, 274.2, 291.1,
        364.35, 355.35, 317.15, 308.8, 293.15, 273.85, 356.0, 356.55,
        290.25, 364.5, 312.8, 283.95, 281.8, 287.35, 313.75, 310.8, 276.45,
        355.3, 285.25, 278.1, 303.8, 346.5, 298.25, 249.1, 305.45, 280.65,
        280.15, 342.05, 294.0, 261.15, 310.05, 360.05, 248.1, 308.45,
        269.65, 278.0, 292.75, 353.55, 363.2, 268.55, 255.95, 372.4, 273.3,
        249.95, 292.45, 317.55, 275.65, 285.7, 320.75, 297.4, 312.5, 255.7,
        280.25, 301.65, 314.65, 262.9, 341.1, 270.3, 291.9, 289.9, 293.9,
        294.35, 310.0, 316.0, 289.75, 260.95, 289.9, 300.25, 312.4, 315.75,
        310.9, 366.15, 338.85, 289.0, 284.55, 288.15, 293.05, 343.8, 280.2,
        314.75, 298.95, 303.05, 289.4, 315.25, 294.8, 320.5, 344.0, 254.55,
        267.1, 254.15, 305.25, 273.15, 287.05, 339.6, 308.15, 317.05,
        310.75, 305.55, 249.55, 342.2, 286.4, 284.7]),np.array([301.8, 344.4, 264.4, 282.7, 256.4, 321.5, 294.75, 283.2, 297.5,
        278.5, 354.0, 321.8, 340.8, 288.9, 312.5, 316.2, 290.0, 301.05,
        311.0, 296.3, 345.5, 304.3, 270.55, 276.5, 281.0, 352.35, 270.4,
        271.3, 280.65, 345.05, 258.0, 362.2, 287.95, 287.95, 292.0, 284.2,
        306.8, 369.45, 285.5, 296.7, 280.4, 287.9, 281.2, 332.0, 310.1,
        275.05, 259.3, 316.0, 298.75, 296.9, 286.65, 258.0, 292.85, 325.1,
        341.7, 287.0, 259.7, 349.0, 270.3, 287.3, 289.3, 343.75, 323.65,
        312.0, 335.5, 303.0, 353.5, 268.35, 344.8, 298.35, 286.65, 360.55,
        297.6, 264.5, 294.7, 270.75, 266.0, 285.95, 272.0, 289.4, 346.0,
        285.0, 285.9, 283.0, 295.8, 276.3, 371.95, 281.85, 288.8, 297.2,
        306.0, 318.25, 305.4, 312.4, 271.0, 295.0, 358.5, 344.95, 330.8,
        305.25, 288.1, 275.95, 365.1, 352.7, 293.0, 362.15, 318.25, 282.4,
        281.8, 285.3, 307.55, 315.8, 271.7, 368.0, 283.75, 277.3, 302.8,
        343.0, 303.95, 251.5, 310.7, 283.15, 282.45, 337.0, 294.0, 273.75,
        308.8, 360.95, 252.0, 315.55, 264.4, 273.95, 287.85, 349.75, 358.5,
        278.3, 272.75, 364.05, 275.0, 258.5, 295.9, 318.95, 278.0, 284.0,
        321.1, 303.9, 306.9, 260.25, 297.0, 302.0, 307.85, 260.9, 338.9,
        264.6, 293.65, 283.0, 299.1, 290.0, 309.0, 316.2, 285.05, 250.1,
        302.4, 298.45, 293.35, 316.6, 314.85, 365.25, 343.1, 290.0, 289.4,
        293.5, 293.5, 343.95, 288.0, 313.95, 298.9, 300.15, 284.6, 314.6,
        293.6, 331.0, 346.95, 256.2, 268.0, 254.0, 310.05, 267.5, 283.45,
        341.85, 308.05, 323.7, 305.85, 305.1, 254.5, 351.2, 284.1, 288.2]),np.array([[310.75, 346.7, 265.7, 286.05, 266.0, 325.75, 305.0, 284.3, 300.7,
        285.85, 357.2, 327.65, 346.15, 288.9, 317.1, 317.9, 294.8, 301.5,
        312.0, 298.0, 346.35, 306.4, 274.6, 276.7, 286.0, 356.45, 275.0,
        271.4, 282.2, 348.3, 258.0, 365.0, 292.8, 287.95, 292.4, 287.0,
        310.3, 373.6, 285.6, 297.6, 287.7, 292.8, 289.4, 345.8, 339.65,
        277.0, 261.95, 319.0, 299.85, 302.7, 286.65, 259.0, 295.0, 333.2,
        343.2, 287.5, 264.2, 349.6, 271.0, 287.4, 291.45, 343.75, 331.0,
        312.0, 344.0, 306.65, 360.0, 283.25, 350.7, 301.65, 289.9, 361.5,
        301.0, 268.3, 302.0, 277.8, 267.9, 285.95, 272.0, 294.0, 347.3,
        286.45, 288.55, 289.0, 306.0, 279.7, 373.8, 284.25, 290.9, 298.25,
        307.1, 323.3, 306.2, 315.0, 276.4, 295.55, 366.0, 357.0, 331.5,
        310.85, 294.4, 277.95, 366.05, 357.0, 293.0, 365.0, 319.25, 285.2,
        281.8, 289.0, 316.0, 315.8, 277.85, 368.45, 285.85, 282.55, 304.65,
        347.45, 305.3, 253.4, 313.4, 285.0, 283.2, 342.75, 295.45, 275.0,
        312.3, 361.7, 252.5, 322.25, 271.35, 278.7, 294.0, 355.0, 364.0,
        278.3, 275.5, 373.55, 276.35, 260.5, 296.75, 318.95, 279.25, 288.0,
        323.0, 304.35, 313.5, 261.8, 297.5, 303.6, 316.75, 267.5, 342.6,
        270.85, 296.5, 291.0, 302.5, 295.5, 311.8, 321.0, 291.25, 262.0,
        302.45, 302.85, 317.8, 319.4, 317.05, 366.7, 345.2, 294.0, 292.45,
        293.5, 295.0, 346.55, 288.0, 315.7, 300.9, 306.6, 290.5, 316.4,
        297.1, 332.45, 346.95, 261.4, 268.35, 260.7, 313.75, 279.1, 289.55,
        344.7, 311.4, 323.7, 311.95, 307.5, 255.0, 353.0, 287.25, 290.45]])
ax.plot_wireframe(X, y, z)
plt.show()

################################################################################################################################################################

#SBI stock market using Decidion tree

data = pd.read_csv('stock market.csv')

data.head(100)

data = pd.read_csv('stock market.csv')

data.dtypes

data = data.set_index(['Date'])

data.head()

vol = data['Vol.']

a=vol[0].strip().split()

a

data['Vol.'] = data['Vol.'].fillna(0.0)

for i in range(data['Vol.'].shape[0]):
    #print(data['Vol.'][i])
    if type(data['Vol.'][i]) != float and data['Vol.'][i].endswith('M'):
        data['Vol.'][i] = data['Vol.'][i][:-1]
        #print(data['Vol.'][i])
    else:
        data['Vol.'][i] = data['Vol.'][i]
        #print(data['Vol.'][i])

for i in range(data['Change %'].shape[0]):
    #print(data['Vol.'][i])
    if type(data['Change %'][i]) != float and data['Change %'][i].endswith('%'):
        data['Change %'][i] = data['Change %'][i][:-1]
        #print(data['Vol.'][i])
    else:
        data['Change %'][i] = data['Change %'][i]
        #print(data['Vol.'][i])

X = data.iloc[:, :-1].values
y = data.iloc[:, -1].values

data.shape, X.shape, y.shape

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

from sklearn.linear_model import LinearRegression

lr = LinearRegression()

lr.fit(X_train, y_train)

y_pred = lr.predict(X_test)

from sklearn.metrics import mean_squared_error, r2_score

mean_squared_error(y_test, y_pred)

r2_score(y_test, y_pred)

from sklearn.tree import DecisionTreeRegressor
dr = DecisionTreeRegressor()
dr.fit(X,y)

y_pred = dr.predict(X)

from sklearn.metrics import mean_squared_error ,r2_score
r2_score(y_pred,y)

import matplotlib.pyplot as plt
plt.scatter(y_pred,y)
plt.show()

#####################################################################

#SBI Stock Market data using Random forest regression

from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor(n_estimators=100)

rf.fit(X,y)

y_pred = rf.predict(X)

from sklearn.metrics import mean_squared_error, r2_score
mean_squared_error(y_pred,y)
r2_score(y_pred,y)

import matplotlib.pyplot as plt
plt.scatter(y_pred,y)
plt.show()

#######################################################################

#SBI market using Support vector regression

from sklearn.svm import SVR
svr = SVR()
svr.fit(X,y)

y_pred = svr.predict(X)
from sklearn.metrics import mean_squared_error, r2_score
mean_squared_error(y_pred,y)
r2_score(y_pred,y)

import matplotlib.pyplot as plt
plt.scatter(y_pred,y)
plt.show()

